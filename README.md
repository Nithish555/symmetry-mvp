# Symmetry

> **The Context OS for AI-Native Work**

Symmetry is a memory and knowledge layer that enables seamless conversation continuity across AI tools. Never lose context when switching between ChatGPT, Claude, Cursor, or any other AI assistant.

[![Version](https://img.shields.io/badge/version-1.0.0-blue)]()
[![Python](https://img.shields.io/badge/python-3.11+-green)]()
[![License](https://img.shields.io/badge/license-MIT-purple)]()

---

## Table of Contents

1. [The Problem](#-the-problem)
2. [The Solution](#-the-solution)
3. [Architecture Overview](#-architecture-overview)
4. [Quick Start](#-quick-start)
5. [Deep Dive: System Layers](#-deep-dive-system-layers)
   - [API Layer](#1-api-layer)
   - [Service Layer](#2-service-layer)
   - [Data Layer](#3-data-layer)
6. [Core Pipelines](#-core-pipelines)
   - [Ingestion Pipeline](#ingestion-pipeline)
   - [Retrieval Pipeline](#retrieval-pipeline)
   - [Recommendation Pipeline](#recommendation-pipeline)
7. [Key Algorithms & Techniques](#-key-algorithms--techniques)
8. [Data Models](#-data-models)
9. [API Reference](#-api-reference)
10. [Configuration](#-configuration)
11. [Project Structure](#-project-structure)

---

## ğŸ¯ The Problem

When you work with AI assistants, your context is fragmented:

```
Monday (ChatGPT):    "I'm building an e-commerce site with React..."
Tuesday (Claude):    "I'm building an e-commerce site with React..." â† Repeating yourself!
Wednesday (Cursor):  "I'm building an e-commerce site with React..." â† Again!
```

**You shouldn't have to re-explain your project every time you switch tools.**

---

## ğŸ’¡ The Solution

Symmetry captures, stores, and retrieves your AI conversation context:

```
Monday (ChatGPT):    "I'm building an e-commerce site with React..."
                            â†“ Symmetry captures this
Tuesday (Claude):    [Symmetry injects context] â†’ Claude already knows your project!
Wednesday (Cursor):  [Symmetry injects context] â†’ Cursor continues seamlessly!
```

### Key Features

| Feature | Description |
|---------|-------------|
| **Cross-LLM Continuity** | Continue conversations across ChatGPT, Claude, Cursor, etc. |
| **Auto Session Detection** | Automatically groups related conversations (96%+ accuracy) |
| **Semantic Search** | Find relevant context using natural language queries |
| **Smart Recommendations** | Get suggestions for relevant past conversations |
| **Knowledge Extraction** | Automatically extracts decisions, facts, and entities |
| **Contradiction Detection** | Warns when you contradict past decisions |

---

## ğŸ—ï¸ Architecture Overview

Symmetry uses a **layered architecture** with two main data stores:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              SYMMETRY SYSTEM                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚   â”‚ ChatGPT â”‚  â”‚ Claude  â”‚  â”‚ Cursor  â”‚  â”‚  Other  â”‚    â† AI Clients        â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                        â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                          â”‚                                                   â”‚
â”‚                          â–¼                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                        API LAYER (FastAPI)                            â”‚  â”‚
â”‚   â”‚  /ingest  /retrieve  /recommend  /sessions  /users  /knowledge       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                                   â”‚
â”‚                          â–¼                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                       SERVICE LAYER                                   â”‚  â”‚
â”‚   â”‚  ChunkingService    EmbeddingService    ExtractionService            â”‚  â”‚
â”‚   â”‚  SessionService     RecommendationService    SummarizationService    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚            â–¼                           â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚   â”‚    MEMORY LAYER     â”‚   â”‚   KNOWLEDGE LAYER   â”‚                        â”‚
â”‚   â”‚                     â”‚   â”‚                     â”‚                        â”‚
â”‚   â”‚   PostgreSQL +      â”‚   â”‚      Neo4j          â”‚                        â”‚
â”‚   â”‚   pgvector          â”‚   â”‚   (Graph DB)        â”‚                        â”‚
â”‚   â”‚                     â”‚   â”‚                     â”‚                        â”‚
â”‚   â”‚ â€¢ Users             â”‚   â”‚ â€¢ Entities          â”‚                        â”‚
â”‚   â”‚ â€¢ Sessions          â”‚   â”‚ â€¢ Relationships     â”‚                        â”‚
â”‚   â”‚ â€¢ Conversations     â”‚   â”‚ â€¢ Decisions         â”‚                        â”‚
â”‚   â”‚ â€¢ Chunks            â”‚   â”‚ â€¢ Facts             â”‚                        â”‚
â”‚   â”‚ â€¢ Embeddings        â”‚   â”‚                     â”‚                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Two Databases?

| Database | Purpose | Strength |
|----------|---------|----------|
| **PostgreSQL + pgvector** | Memory Layer | Fast vector similarity search, relational data, ACID compliance |
| **Neo4j** | Knowledge Layer | Graph traversal, relationship queries, entity connections |

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/symmetry-mvp.git
cd symmetry-mvp

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp env.example .env
# Edit .env with your credentials
```

### 2. Database Setup

**PostgreSQL (Supabase):**
```bash
# Run in Supabase SQL Editor
scripts/setup_db.sql
```

**Neo4j (Optional but recommended):**
```bash
# Run in Neo4j Browser
scripts/setup_neo4j.cypher
```

### 3. Run the Server

```bash
uvicorn app.main:app --reload --port 8000
```

### 4. Register & Start Using

```bash
# Register
curl -X POST http://localhost:8000/api/v1/users/register \
  -H "Content-Type: application/json" \
  -d '{"email": "you@example.com"}'

# Save your API key from the response!
```

---

## ğŸ”¬ Deep Dive: System Layers

### 1. API Layer

**Location:** `app/api/routes/`

The API layer handles HTTP requests and responses using FastAPI. Each route file handles a specific domain:

```
app/api/routes/
â”œâ”€â”€ users.py          # User registration, authentication
â”œâ”€â”€ ingest.py         # Store conversations (POST /ingest)
â”œâ”€â”€ retrieve.py       # Get context (POST /retrieve)
â”œâ”€â”€ recommend.py      # Get recommendations (POST /recommend)
â”œâ”€â”€ sessions.py       # Session management (CRUD)
â”œâ”€â”€ conversations.py  # Conversation management
â”œâ”€â”€ memories.py       # Memory operations
â””â”€â”€ knowledge.py      # Knowledge graph operations
```

#### Key Concepts:

**Dependency Injection (`app/api/dependencies.py`):**
```python
# Every route gets these injected automatically:
user_id: str = Depends(get_current_user_id)      # From API key
postgres: PostgresDB = Depends(get_postgres)      # Database connection
neo4j: Neo4jDB = Depends(get_neo4j)              # Graph database
config: Settings = Depends(get_config)            # App settings
```

**Authentication:**
- All endpoints require `Authorization: Bearer sk_your_api_key` header
- API key is validated against the `users` table
- User ID is extracted and passed to all operations

---

### 2. Service Layer

**Location:** `app/services/`

The service layer contains the core business logic. Each service is a focused module:

```
app/services/
â”œâ”€â”€ chunking.py       # Text splitting with semantic awareness
â”œâ”€â”€ embedding.py      # Vector embedding generation
â”œâ”€â”€ extraction.py     # Knowledge extraction from text
â”œâ”€â”€ session.py        # Session detection and linking
â”œâ”€â”€ recommendation.py # Recommendation scoring algorithm
â””â”€â”€ summarization.py  # Context summary generation
```

#### 2.1 Chunking Service (`chunking.py`)

**Purpose:** Split conversations into smaller pieces for embedding while preserving meaning.

**Key Innovation: Semantic-Aware Chunking**

Unlike simple character-based splitting, Symmetry's chunker:

1. **Splits at sentence boundaries** - Never cuts mid-thought
2. **Preserves negations** - "NOT going to use X" stays together
3. **Keeps decisions with reasons** - "I chose X because Y" stays together
4. **Protects code blocks** - Never splits code
5. **Message-aware** - Prefers splitting between USER/ASSISTANT messages

```python
# Bad chunking (character-based):
Chunk 1: "I'm NOT going to use Mon"
Chunk 2: "goDB because it lacks ACID"  # Lost the negation context!

# Good chunking (semantic-aware):
Chunk 1: "I'm NOT going to use MongoDB because it lacks ACID compliance."
```

**Decision Boundary Detection:**

The chunker identifies patterns that shouldn't be split:

```python
# Positive decisions
"I'll use", "I decided", "going with", "let's use"

# Negative decisions (CRITICAL - keeps negation with subject)
"NOT going to", "won't use", "decided against", "ruled out"

# Comparisons
"better than", "prefer X over", "instead of"

# Conclusions
"because", "therefore", "the reason is"
```

**Chunking Modes:**

| Mode | Function | Use Case |
|------|----------|----------|
| `chunk_conversation_semantic()` | Semantic-aware splitting | Default, recommended |
| `chunk_by_exchange()` | User-Assistant pairs | Keep Q&A together |
| `chunk_with_context()` | Chunks with surrounding context | Better retrieval |

---

#### 2.2 Embedding Service (`embedding.py`)

**Purpose:** Convert text into vector representations for semantic search.

**How It Works:**

```
Text: "I chose PostgreSQL for my e-commerce project"
         â”‚
         â–¼
    OpenAI/Azure API (text-embedding-3-large)
         â”‚
         â–¼
Vector: [0.0234, -0.0891, 0.1456, ..., 0.0023]  (3072 floats)
```

**Why Embeddings?**

Embeddings capture **semantic meaning**, not just keywords:

```
Query: "What database did I pick?"
         â†“ Similar vector to:
Stored: "I chose PostgreSQL for the project"

Even though "pick" â‰  "chose" and "database" â‰  "PostgreSQL",
the vectors are close because the MEANING is similar.
```

**Configuration:**

| Setting | Default | Description |
|---------|---------|-------------|
| `embedding_model` | text-embedding-3-large | OpenAI model |
| `embedding_dimensions` | 3072 | Vector size |
| `provider` | azure_openai | OpenAI or Azure |

---

#### 2.3 Extraction Service (`extraction.py`)

**Purpose:** Extract structured knowledge (entities, relationships, decisions) from conversations.

**What Gets Extracted:**

```
Conversation: "I'll use PostgreSQL. My colleague suggested MongoDB but I ruled it out."
                                    â”‚
                                    â–¼
                            LLM Analysis (GPT-4o-mini)
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTITIES:                                                                    â”‚
â”‚   â€¢ PostgreSQL (Tool) - "Relational database"                               â”‚
â”‚   â€¢ MongoDB (Tool) - "NoSQL database"                                       â”‚
â”‚                                                                              â”‚
â”‚ RELATIONSHIPS:                                                               â”‚
â”‚   â€¢ User â”€â”€CHOSEâ”€â”€â†’ PostgreSQL (confidence: 0.95, status: decided)          â”‚
â”‚   â€¢ User â”€â”€REJECTEDâ”€â”€â†’ MongoDB (confidence: 0.85, status: rejected)         â”‚
â”‚   â€¢ User â”€â”€CONSIDERINGâ”€â”€â†’ MongoDB (attributed_to: colleague)                â”‚
â”‚                                                                              â”‚
â”‚ FACTS:                                                                       â”‚
â”‚   â€¢ User WORKS_ON E-commerce Project (temporal: current)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Decision Status Classification:**

| User Says | Status | Type | Confidence |
|-----------|--------|------|------------|
| "I'll use X", "I decided on X" | decided | CHOSE | 0.85-1.0 |
| "I think X", "Leaning toward X" | exploring | CONSIDERING | 0.5-0.7 |
| "Maybe X", "What about X?" | exploring | CONSIDERING | 0.3-0.5 |
| "I won't use X", "Ruled out X" | rejected | REJECTED | 0.8-1.0 |

**Critical: Negation Detection**

The extraction prompt is specifically designed to catch negations:

```python
# These are NOT decisions to USE something:
"I'm NOT going to use MongoDB"     â†’ REJECTED (not CHOSE!)
"I decided against Redis"          â†’ REJECTED
"We ruled out DynamoDB"            â†’ REJECTED
```

**Source Attribution:**

Every extracted relationship tracks WHO said it:

| Source | Meaning |
|--------|---------|
| `user` | The person in the conversation |
| `colleague` | Someone the user mentioned |
| `article` | External documentation/blog |
| `ai_suggestion` | The AI assistant suggested it |

---

#### 2.4 Session Service (`session.py`)

**Purpose:** Automatically detect and link related conversations into sessions.

**How Session Detection Works:**

```
New Conversation: "Help me add Stripe payments to my React store"
                                    â”‚
                                    â–¼
                        Generate Conversation Embedding
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEARCH EXISTING SESSIONS BY SIMILARITY                                       â”‚
â”‚                                                                              â”‚
â”‚ SELECT * FROM sessions                                                       â”‚
â”‚ WHERE 1 - (embedding <=> new_embedding) > 0.5                               â”‚
â”‚ ORDER BY embedding <=> new_embedding                                         â”‚
â”‚ LIMIT 5                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULTS:                                                                     â”‚
â”‚                                                                              â”‚
â”‚   Session                    â”‚ Similarity â”‚ Recency Boost â”‚ Final Score    â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   E-commerce Project         â”‚    0.92    â”‚    +0.08      â”‚    0.96  âœ“     â”‚
â”‚   React Learning             â”‚    0.71    â”‚    +0.02      â”‚    0.73        â”‚
â”‚   Personal Blog              â”‚    0.45    â”‚    +0.00      â”‚    0.45        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                        DECISION LOGIC:
                        
    IF score > 0.85 AND auto_link_session=true:
        â†’ AUTO-LINK (high confidence)
    ELIF score > 0.70:
        â†’ SUGGEST (user confirms)
    ELSE:
        â†’ STANDALONE (no match)
```

**Confidence Thresholds:**

| Confidence | Action | User Control |
|------------|--------|--------------|
| > 85% | Auto-link (if enabled) | `auto_link_session: true` |
| 70-85% | Suggest to user | User must confirm |
| < 70% | Keep standalone | No suggestion |

**Recency Boost:**

Recent sessions get a score boost to prefer active projects:

```python
if hours_ago <= 24:
    recency_boost = 0.1 * (1 - hours_ago / 24)
else:
    recency_boost = 0.0
```

---

#### 2.5 Recommendation Service (`recommendation.py`)

**Purpose:** Find relevant context before starting a new conversation.

**Scoring Algorithm:**

```
Final Score = (Relevance Ã— 0.60) + (Recency Ã— 0.25) + (Quality Ã— 0.15)
```

**Relevance Score (60%):**
```
Base: Cosine similarity from embedding search
Bonus: +0.1 per matching topic
Bonus: +0.05 per matching entity
```

**Recency Score (25%):**
```
< 24 hours ago:  1.0
1-7 days ago:    0.8 â†’ 0.5 (linear decay)
7-30 days ago:   0.5 â†’ 0.1 (linear decay)
> 30 days ago:   0.0
```

**Quality Score (15%):**
```
Has summary:     +0.3
Has topics:      +0.2
Has entities:    +0.2
Messages â‰¥ 10:   +0.3
Has decisions:   +0.2 (from Neo4j)
```

**Auto-Selection:**

A recommendation is auto-selected if:
1. Score > 0.85 **AND**
2. Margin > 0.20 (gap from second-best)

```python
if top.score > 0.85 and (top.score - second.score) > 0.20:
    auto_select = top
```

**Knowledge Graph Expansion:**

The recommendation service uses Neo4j to expand queries:

```
User Query: "implement caching"
         â”‚
         â–¼
    Extract Keywords: ["caching"]
         â”‚
         â–¼
    Neo4j Graph Traversal:
    caching â†’ Redis â†’ session storage â†’ TTL
         â”‚
         â–¼
    Expanded Search Terms: ["caching", "Redis", "session storage", "TTL"]
```

---

#### 2.6 Summarization Service (`summarization.py`)

**Purpose:** Generate human-readable summaries from retrieved context.

**Input:**
- Query (what user is asking about)
- Chunks (relevant conversation snippets)
- Decisions (from Neo4j)
- Facts (from Neo4j)
- Entities (from Neo4j)

**Output:**
```
"You chose PostgreSQL for your e-commerce project because you need 
relational data for products, orders, and users. Prisma was recommended 
as the ORM. You're using React for the frontend and considering Stripe 
for payments."
```

---

### 3. Data Layer

**Location:** `app/db/`

#### 3.1 PostgreSQL Client (`postgres.py`)

**Purpose:** Handle all Memory Layer operations.

**Key Operations:**

| Category | Methods |
|----------|---------|
| **Users** | `create_user()`, `get_user_by_api_key()`, `get_user_by_email()` |
| **Sessions** | `create_session()`, `get_session()`, `list_sessions()`, `search_sessions_by_embedding()` |
| **Conversations** | `create_conversation()`, `get_conversation()`, `link_conversation_to_session()` |
| **Chunks** | `create_chunk()`, `search_chunks()`, `search_chunks_hybrid()` |
| **Suggestions** | `create_session_suggestion()`, `get_session_suggestion_stats()` |

**Vector Search with pgvector:**

```sql
-- Cosine similarity search
SELECT content, 1 - (embedding <=> query_embedding) as similarity
FROM chunks
WHERE user_id = $user_id
  AND 1 - (embedding <=> query_embedding) > 0.5
ORDER BY embedding <=> query_embedding
LIMIT 5
```

**Hybrid Search (Semantic + Keyword):**

```python
async def search_chunks_hybrid(user_id, embedding, keywords, semantic_weight=0.7):
    """
    Combines:
    - Semantic similarity (70%): Vector cosine distance
    - Keyword matching (30%): ILIKE text search
    
    Helps catch cases where:
    - Semantic search misses due to vocabulary mismatch
    - Keywords catch what embeddings miss
    """
```

**Tiered Confidence Results:**

```python
async def search_chunks_tiered(user_id, embedding, limit=10):
    """
    Returns results in confidence tiers:
    - High (â‰¥0.7): Very relevant
    - Medium (0.5-0.7): Possibly relevant  
    - Low (0.3-0.5): Might be related
    """
```

---

#### 3.2 Neo4j Client (`neo4j.py`)

**Purpose:** Handle all Knowledge Layer operations.

**Graph Structure:**

```
         (User)
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚           â”‚          â”‚
   CHOSE     REJECTED   CONSIDERING
     â”‚           â”‚          â”‚
     â–¼           â–¼          â–¼
(PostgreSQL) (MongoDB)   (Redis)
     â”‚
   USED_FOR
     â”‚
     â–¼
(E-commerce Project)
     â”‚
  â”Œâ”€â”€â”´â”€â”€â”
USES   INTEGRATES
  â”‚       â”‚
  â–¼       â–¼
(React) (Stripe)
```

**Key Operations:**

| Category | Methods |
|----------|---------|
| **Entities** | `create_entity()`, `get_entities()`, `find_related_entities()` |
| **Relationships** | `create_relationship()`, `get_decisions()`, `get_exploring()`, `get_rejected()` |
| **Facts** | `create_temporal_fact()`, `get_current_facts()` |
| **Validation** | `detect_contradictions()`, `verify_relationship()`, `get_unverified_knowledge()` |

**Relationship Properties:**

```python
{
    "id": "uuid",
    "created_at": "2026-01-19T10:30:00Z",
    "confidence": 0.9,           # 0.0-1.0
    "status": "decided",         # decided, exploring, rejected
    "verified": False,           # User hasn't verified yet
    "attributed_to": "user",     # user, colleague, article, ai_suggestion
    "temporal": "current",       # current, past, future
    "conversation_id": "...",    # Source conversation
    "source": "chatgpt"          # Source platform
}
```

**Contradiction Detection:**

```cypher
// Find cases where user chose something, then chose something else in same category
MATCH (u:User {user_id: $user_id})-[r1:CHOSE]->(t1)
MATCH (u)-[r2:CHOSE]->(t2)
WHERE t1 <> t2
AND labels(t1) = labels(t2)  // Same category (both databases, both frameworks, etc.)
AND r1.created_at < r2.created_at
RETURN t1.name as old_decision, t2.name as new_decision, labels(t1)[0] as category
```

---

## ğŸ”„ Core Pipelines

### Ingestion Pipeline

**Endpoint:** `POST /api/v1/ingest`

**Complete Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INGESTION PIPELINE                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT:
{
  "source": "chatgpt",
  "messages": [
    {"role": "user", "content": "I want to build an e-commerce site..."},
    {"role": "assistant", "content": "Great! Let's use React and..."}
  ],
  "auto_link_session": true
}
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: GENERATE SUMMARY                                                     â”‚
â”‚                                                                              â”‚
â”‚ LLM (GPT-4o-mini) analyzes conversation:                                    â”‚
â”‚   â†’ Summary: "User building e-commerce with React, chose PostgreSQL"        â”‚
â”‚   â†’ Topics: ["e-commerce", "React", "PostgreSQL"]                           â”‚
â”‚   â†’ Entities: ["React", "PostgreSQL", "Stripe"]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: GENERATE CONVERSATION EMBEDDING                                      â”‚
â”‚                                                                              â”‚
â”‚ Summary text â†’ text-embedding-3-large â†’ [3072-dim vector]                   â”‚
â”‚ This embedding represents the ENTIRE conversation's meaning                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: SESSION DETECTION                                                    â”‚
â”‚                                                                              â”‚
â”‚ Search existing sessions by embedding similarity:                            â”‚
â”‚                                                                              â”‚
â”‚   E-commerce Project    â”‚ 0.96 similarity â”‚ AUTO-LINK âœ“                     â”‚
â”‚   React Learning        â”‚ 0.73 similarity â”‚                                  â”‚
â”‚   Personal Blog         â”‚ 0.45 similarity â”‚                                  â”‚
â”‚                                                                              â”‚
â”‚ Decision: Auto-link to "E-commerce Project" (0.96 > 0.85 threshold)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: STORE CONVERSATION                                                   â”‚
â”‚                                                                              â”‚
â”‚ INSERT INTO conversations (user_id, source, raw_messages, session_id,       â”‚
â”‚                            summary, topics, entities, embedding)            â”‚
â”‚ VALUES (...)                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: CHUNK AND EMBED                                                      â”‚
â”‚                                                                              â”‚
â”‚ Semantic Chunking:                                                           â”‚
â”‚   "USER: I want to build..."  â†’  Chunk 0 (preserves meaning)                â”‚
â”‚   "ASSISTANT: Great! Let's..." â†’  Chunk 1 (keeps Q&A context)               â”‚
â”‚                                                                              â”‚
â”‚ Each chunk â†’ Embedding API â†’ Store in chunks table                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: EXTRACT KNOWLEDGE (Neo4j)                                            â”‚
â”‚                                                                              â”‚
â”‚ LLM extracts structured knowledge:                                           â”‚
â”‚                                                                              â”‚
â”‚   ENTITIES:                                                                  â”‚
â”‚     â€¢ PostgreSQL (Tool)                                                      â”‚
â”‚     â€¢ React (Technology)                                                     â”‚
â”‚     â€¢ E-commerce Project (Project)                                           â”‚
â”‚                                                                              â”‚
â”‚   RELATIONSHIPS:                                                             â”‚
â”‚     â€¢ User â”€â”€CHOSEâ”€â”€â†’ PostgreSQL (confidence: 0.95)                         â”‚
â”‚     â€¢ User â”€â”€CHOSEâ”€â”€â†’ React (confidence: 0.90)                              â”‚
â”‚     â€¢ Project â”€â”€USESâ”€â”€â†’ PostgreSQL                                          â”‚
â”‚                                                                              â”‚
â”‚   FACTS:                                                                     â”‚
â”‚     â€¢ User WORKS_ON E-commerce Project (temporal: current)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: UPDATE SESSION EMBEDDING                                             â”‚
â”‚                                                                              â”‚
â”‚ Recalculate session embedding as average of all conversation embeddings     â”‚
â”‚ This improves future session matching accuracy                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
OUTPUT:
{
  "conversation_id": "conv-123",
  "chunks_created": 4,
  "entities_extracted": 3,
  "relationships_created": 3,
  "linked_session_id": "session-456",
  "session_suggestion": {
    "suggested_session": {"name": "E-commerce Project"},
    "confidence": 0.96,
    "auto_linked": true
  }
}
```

**Append Mode:**

When updating an existing conversation:

```python
# Option 1: Send ALL messages (default)
{
  "conversation_id": "conv-123",
  "messages": [old_msg1, old_msg2, new_msg3, new_msg4],  # ALL messages
  "append_only": false  # System compares to find new ones
}

# Option 2: Send ONLY new messages
{
  "conversation_id": "conv-123", 
  "messages": [new_msg3, new_msg4],  # ONLY new messages
  "append_only": true  # System appends directly
}
```

---

### Retrieval Pipeline

**Endpoint:** `POST /api/v1/retrieve`

**Four Modes:**

| Mode | Use Case | Required Params |
|------|----------|-----------------|
| `query` | Find specific info | `query` |
| `session` | Continue a project | `session_id` |
| `conversation` | Continue specific chat | `conversation_id` |
| `full` | Get ALL context | - |

**Query Mode Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QUERY MODE RETRIEVAL                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: { "mode": "query", "query": "what database did I choose?" }
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: EXTRACT KEYWORDS                                                     â”‚
â”‚                                                                              â”‚
â”‚ Query: "what database did I choose?"                                        â”‚
â”‚ Keywords: ["database", "choose"]                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: KNOWLEDGE GRAPH EXPANSION (Neo4j)                                    â”‚
â”‚                                                                              â”‚
â”‚ Find related entities from user's graph:                                    â”‚
â”‚   "database" â†’ PostgreSQL â†’ ACID, relational, Prisma                        â”‚
â”‚                                                                              â”‚
â”‚ Expanded terms: ["database", "choose", "PostgreSQL", "ACID", "Prisma"]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: GENERATE QUERY EMBEDDING                                             â”‚
â”‚                                                                              â”‚
â”‚ "what database did I choose?" â†’ [3072-dim vector]                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: HYBRID SEARCH                                                        â”‚
â”‚                                                                              â”‚
â”‚ Combines:                                                                    â”‚
â”‚   â€¢ Semantic: Vector similarity (70% weight)                                â”‚
â”‚   â€¢ Keyword: Text matching on expanded terms (30% weight)                   â”‚
â”‚                                                                              â”‚
â”‚ Results:                                                                     â”‚
â”‚   1. "I recommend PostgreSQL because..."  (combined: 0.91)                  â”‚
â”‚   2. "PostgreSQL is great for relational..."  (combined: 0.87)              â”‚
â”‚   3. "You'll need tables for products..."  (combined: 0.82)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: FETCH KNOWLEDGE (Neo4j)                                              â”‚
â”‚                                                                              â”‚
â”‚ Decisions: [PostgreSQL (CHOSE, confidence: 0.95)]                           â”‚
â”‚ Facts: [User WORKS_ON E-commerce Project]                                   â”‚
â”‚ Entities: [PostgreSQL, React, Stripe]                                       â”‚
â”‚ Contradictions: [] (none detected)                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: BUILD CONTEXT PROMPT                                                 â”‚
â”‚                                                                              â”‚
â”‚ [CONTEXT FROM PREVIOUS AI CONVERSATIONS - PROVIDED BY SYMMETRY]             â”‚
â”‚                                                                              â”‚
â”‚ ## âœ… Confirmed Decisions:                                                   â”‚
â”‚ - PostgreSQL (Reason: ACID compliance, relational data needs)               â”‚
â”‚                                                                              â”‚
â”‚ ## Current Facts:                                                            â”‚
â”‚ - User WORKS_ON E-commerce Project                                          â”‚
â”‚                                                                              â”‚
â”‚ ## Relevant Past Discussions:                                                â”‚
â”‚ - "I recommend PostgreSQL because you need relational data..."              â”‚
â”‚                                                                              â”‚
â”‚ [END SYMMETRY CONTEXT]                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: GENERATE SUMMARY                                                     â”‚
â”‚                                                                              â”‚
â”‚ LLM creates human-readable summary:                                          â”‚
â”‚ "You chose PostgreSQL for your e-commerce project because you need          â”‚
â”‚  relational data for products, orders, and users."                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
OUTPUT:
{
  "summary": "You chose PostgreSQL for your e-commerce project...",
  "context_prompt": "[CONTEXT FROM PREVIOUS AI CONVERSATIONS...]",
  "decisions": [{"content": "PostgreSQL", "reason": "ACID compliance"}],
  "facts": [{"subject": "User", "predicate": "WORKS_ON", "object": "E-commerce"}],
  "entities": ["PostgreSQL", "React", "Stripe"],
  "chunks_found": 3
}
```

**Session Mode:**

Returns ALL conversations in a session in chronological order:

```
[CONTEXT FROM PREVIOUS AI CONVERSATIONS - PROVIDED BY SYMMETRY]

## Session: E-commerce Project
Description: Building online store with React/Node/PostgreSQL

## Complete Session History (chronological):

### [chatgpt] - 2026-01-15
**USER**: I want to build an e-commerce site...
**ASSISTANT**: Great! Let's start with the tech stack...

### [claude] - 2026-01-16
**USER**: Help me design the database schema...
**ASSISTANT**: For e-commerce, you need these tables...

### [cursor] - 2026-01-17
**USER**: Now let's integrate Stripe...
**ASSISTANT**: Here's how to set up Stripe...

## âœ… Confirmed Decisions:
- PostgreSQL (Reason: relational data needs)
- React (Reason: component-based UI)
- Stripe (Reason: best payment docs)

[END SYMMETRY CONTEXT]
```

---

### Recommendation Pipeline

**Endpoint:** `POST /api/v1/recommend`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RECOMMENDATION PIPELINE                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: { "query": "implement Stripe payments" }
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: ANALYZE QUERY                                                        â”‚
â”‚                                                                              â”‚
â”‚ Extract topics: ["payments", "Stripe", "implementation"]                    â”‚
â”‚ Extract entities: ["Stripe"]                                                â”‚
â”‚ Generate embedding: [3072-dim vector]                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: KNOWLEDGE GRAPH EXPANSION                                            â”‚
â”‚                                                                              â”‚
â”‚ Neo4j traversal from "Stripe", "payments":                                  â”‚
â”‚   Stripe â†’ E-commerce Project â†’ PostgreSQL â†’ products table                 â”‚
â”‚                                                                              â”‚
â”‚ Expanded entities: ["Stripe", "E-commerce Project", "checkout"]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: SEARCH SESSIONS & CONVERSATIONS                                      â”‚
â”‚                                                                              â”‚
â”‚ Sessions (by embedding similarity):                                          â”‚
â”‚   E-commerce Project â”‚ similarity: 0.89                                     â”‚
â”‚   React Learning     â”‚ similarity: 0.52                                     â”‚
â”‚                                                                              â”‚
â”‚ Standalone Conversations (not in sessions):                                  â”‚
â”‚   Payment discussion â”‚ similarity: 0.68                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: SCORE AND RANK                                                       â”‚
â”‚                                                                              â”‚
â”‚ For each candidate:                                                          â”‚
â”‚   Relevance = similarity + topic_bonus + entity_bonus                       â”‚
â”‚   Recency = time_decay_function(last_activity)                              â”‚
â”‚   Quality = has_summary + has_topics + message_count                        â”‚
â”‚                                                                              â”‚
â”‚   Final = (Relevance Ã— 0.60) + (Recency Ã— 0.25) + (Quality Ã— 0.15)         â”‚
â”‚                                                                              â”‚
â”‚ Results:                                                                     â”‚
â”‚   E-commerce Project â”‚ final: 0.91 â”‚ AUTO-SELECT âœ“                          â”‚
â”‚   Payment discussion â”‚ final: 0.68 â”‚                                        â”‚
â”‚   React Learning     â”‚ final: 0.52 â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
OUTPUT:
{
  "recommendations": [
    {
      "type": "session",
      "name": "E-commerce Project",
      "score": {"relevance": 0.89, "recency": 1.0, "quality": 0.85, "final": 0.91},
      "auto_select": true
    },
    ...
  ],
  "auto_selected": {"type": "session", "name": "E-commerce Project"},
  "query_analysis": {"topics": ["payments", "Stripe"], "entities": ["Stripe"]}
}
```

---

## ğŸ§  Key Algorithms & Techniques

### 1. Vector Similarity Search

**Cosine Similarity:**

```
                    â†‘ Dimension 2
                    â”‚
                    â”‚     * "PostgreSQL database"
                    â”‚    /
                    â”‚   /  Î¸ = small angle = HIGH similarity
                    â”‚  /
                    â”‚ /
                    â”‚/________* "what database?" (query)
                    â”‚\
                    â”‚ \
                    â”‚  \  Î¸ = large angle = LOW similarity  
                    â”‚   \
                    â”‚    * "cooking recipes"
                    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Dimension 1

Cosine Similarity = cos(Î¸)
  - Î¸ = 0Â°   â†’ similarity = 1.0 (identical meaning)
  - Î¸ = 90Â°  â†’ similarity = 0.0 (unrelated)
```

**pgvector Operator:**
```sql
-- <=> is cosine distance (1 - similarity)
SELECT 1 - (embedding <=> query_embedding) as similarity
FROM chunks
ORDER BY embedding <=> query_embedding
```

### 2. IVFFlat Index

**Problem:** Comparing query to ALL vectors is O(n) - slow!

**Solution:** Cluster vectors, only search relevant clusters:

```
Without Index:
  Query â†’ Compare with 100,000 vectors â†’ O(n) = SLOW

With IVFFlat (100 clusters):
  Query â†’ Find nearest cluster â†’ Search ~1,000 vectors â†’ O(n/k) = FAST

CREATE INDEX ON chunks USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### 3. Semantic-Aware Chunking

**Key Patterns Protected from Splitting:**

```python
# Negations (CRITICAL)
"NOT going to", "won't use", "decided against"

# Decisions with reasons
"because", "therefore", "the reason is"

# Comparisons
"better than", "prefer X over", "instead of"

# Code blocks
```code``` markers, inline `code`

# Lists
"first", "second", "1.", "2."
```

### 4. Session Detection Algorithm

```python
def detect_session(conversation_embedding, user_sessions):
    # 1. Vector similarity search
    similar_sessions = search_by_embedding(conversation_embedding)
    
    # 2. Add recency boost
    for session in similar_sessions:
        if session.last_activity < 24_hours_ago:
            session.score += 0.1 * (1 - hours_ago / 24)
    
    # 3. Apply decision rules
    top = similar_sessions[0]
    second = similar_sessions[1] if len > 1 else None
    
    if top.score > 0.85 and (not second or top.score - second.score > 0.15):
        return AutoLink(top)
    elif top.score > 0.70:
        return Suggest(top)
    else:
        return Standalone()
```

### 5. Knowledge Graph Expansion

```cypher
// Find entities related to search terms
UNWIND $search_terms AS term
MATCH (start)
WHERE start.user_id = $user_id
AND toLower(start.name) CONTAINS toLower(term)

// Traverse 1-2 hops to find related entities
MATCH path = (start)-[*1..2]-(related)
WHERE related.user_id = $user_id

RETURN DISTINCT related.name
ORDER BY length(path) ASC, COUNT(*) DESC
LIMIT 10
```

---

## ğŸ“Š Data Models

### PostgreSQL Schema

```sql
USERS
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ email (TEXT, UNIQUE)
â”œâ”€â”€ api_key (TEXT, UNIQUE)
â””â”€â”€ created_at (TIMESTAMP)
        â”‚
        â”‚ 1:N
        â–¼
SESSIONS
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (UUID, FK)
â”œâ”€â”€ name (TEXT)
â”œâ”€â”€ description (TEXT)
â”œâ”€â”€ topics (TEXT[])
â”œâ”€â”€ entities (TEXT[])
â”œâ”€â”€ embedding (VECTOR 3072)
â”œâ”€â”€ conversation_count (INT)
â””â”€â”€ last_activity (TIMESTAMP)
        â”‚
        â”‚ 1:N
        â–¼
CONVERSATIONS
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (UUID, FK)
â”œâ”€â”€ session_id (UUID, FK, nullable)
â”œâ”€â”€ source (TEXT: chatgpt, claude, cursor)
â”œâ”€â”€ raw_messages (JSONB)
â”œâ”€â”€ summary (TEXT)
â”œâ”€â”€ topics (TEXT[])
â”œâ”€â”€ entities (TEXT[])
â”œâ”€â”€ embedding (VECTOR 3072)
â”œâ”€â”€ session_status (TEXT: standalone, linked)
â”œâ”€â”€ has_decisions (BOOLEAN)
â”œâ”€â”€ has_facts (BOOLEAN)
â””â”€â”€ created_at (TIMESTAMP)
        â”‚
        â”‚ 1:N
        â–¼
CHUNKS
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ conversation_id (UUID, FK)
â”œâ”€â”€ user_id (UUID, FK)
â”œâ”€â”€ content (TEXT)
â”œâ”€â”€ embedding (VECTOR 3072)
â””â”€â”€ chunk_index (INT)
```

### Neo4j Graph Model

```
Node Types:
â”œâ”€â”€ User          {user_id}
â”œâ”€â”€ Tool          {name, description}
â”œâ”€â”€ Technology    {name, description}
â”œâ”€â”€ Project       {name, description}
â”œâ”€â”€ Company       {name}
â””â”€â”€ Concept       {name}

Relationship Types:
â”œâ”€â”€ CHOSE         {confidence, status, reason, verified, temporal}
â”œâ”€â”€ REJECTED      {confidence, reason}
â”œâ”€â”€ CONSIDERING   {confidence, attributed_to}
â”œâ”€â”€ PREFERS       {strength, reason}
â”œâ”€â”€ USES          {temporal}
â”œâ”€â”€ WORKS_ON      {valid_from, valid_to}
â””â”€â”€ RELATED_TO    {description}
```

---

## ğŸ“– API Reference

### Authentication

All endpoints require Bearer token:
```bash
Authorization: Bearer sk_your_api_key
```

### Endpoints

#### Users

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/users/register` | Register new user |

```bash
curl -X POST http://localhost:8000/api/v1/users/register \
  -H "Content-Type: application/json" \
  -d '{"email": "user@example.com"}'
```

#### Ingest

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/ingest` | Store a conversation |

```bash
curl -X POST http://localhost:8000/api/v1/ingest \
  -H "Authorization: Bearer sk_..." \
  -H "Content-Type: application/json" \
  -d '{
    "source": "chatgpt",
    "messages": [
      {"role": "user", "content": "..."},
      {"role": "assistant", "content": "..."}
    ],
    "auto_link_session": true
  }'
```

#### Retrieve

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/retrieve` | Get context |

```bash
# Query mode
curl -X POST http://localhost:8000/api/v1/retrieve \
  -H "Authorization: Bearer sk_..." \
  -d '{"mode": "query", "query": "what database did I choose?"}'

# Session mode
curl -X POST http://localhost:8000/api/v1/retrieve \
  -d '{"mode": "session", "session_id": "..."}'

# Full mode
curl -X POST http://localhost:8000/api/v1/retrieve \
  -d '{"mode": "full", "limit": 10}'
```

#### Recommend

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/recommend` | Get recommendations |

```bash
curl -X POST http://localhost:8000/api/v1/recommend \
  -H "Authorization: Bearer sk_..." \
  -d '{"query": "continue e-commerce project"}'
```

#### Sessions

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/sessions` | List sessions |
| POST | `/api/v1/sessions` | Create session |
| GET | `/api/v1/sessions/{id}` | Get session |
| PATCH | `/api/v1/sessions/{id}` | Update session |
| DELETE | `/api/v1/sessions/{id}` | Delete session |
| POST | `/api/v1/sessions/{id}/conversations` | Link conversation |
| POST | `/api/v1/sessions/confirm-link` | Confirm suggestion |

---

## âš™ï¸ Configuration

### Environment Variables

```env
# Database (Supabase)
DATABASE_URL=postgresql://...
SUPABASE_URL=https://...
SUPABASE_KEY=...

# Neo4j (Optional)
NEO4J_URI=neo4j+s://...
NEO4J_USER=neo4j
NEO4J_PASSWORD=...

# LLM Provider
LLM_PROVIDER=azure_openai  # or "openai"

# Azure OpenAI - Chat
AZURE_OPENAI_ENDPOINT=https://...
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini

# Azure OpenAI - Embeddings
AZURE_OPENAI_EMBEDDING_ENDPOINT=https://...
AZURE_OPENAI_EMBEDDING_API_KEY=...
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-large

# Settings
CHUNK_SIZE=500
CHUNK_OVERLAP=50
SIMILARITY_THRESHOLD=0.7
```

### Configuration Class (`app/config.py`)

```python
class Settings(BaseSettings):
    # Database
    supabase_url: str
    supabase_key: str
    database_url: str
    
    # Neo4j
    neo4j_uri: str
    neo4j_user: str
    neo4j_password: str
    
    # LLM
    llm_provider: str = "openai"
    openai_api_key: Optional[str] = None
    azure_openai_endpoint: Optional[str] = None
    azure_openai_api_key: Optional[str] = None
    
    # App settings
    chunk_size: int = 500
    chunk_overlap: int = 50
    embedding_model: str = "text-embedding-3-large"
    llm_model: str = "gpt-4o-mini"
    similarity_threshold: float = 0.7
```

---

## ğŸ“ Project Structure

```
symmetry-mvp-v2/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py                  # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dependencies.py        # Dependency injection (auth, DB)
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ users.py           # User registration
â”‚   â”‚       â”œâ”€â”€ ingest.py          # POST /ingest
â”‚   â”‚       â”œâ”€â”€ retrieve.py        # POST /retrieve
â”‚   â”‚       â”œâ”€â”€ recommend.py       # POST /recommend
â”‚   â”‚       â”œâ”€â”€ sessions.py        # Session CRUD
â”‚   â”‚       â”œâ”€â”€ conversations.py   # Conversation management
â”‚   â”‚       â”œâ”€â”€ memories.py        # Memory operations
â”‚   â”‚       â””â”€â”€ knowledge.py       # Knowledge graph operations
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postgres.py            # PostgreSQL client (Memory Layer)
â”‚   â”‚   â””â”€â”€ neo4j.py               # Neo4j client (Knowledge Layer)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chunking.py            # Semantic text chunking
â”‚   â”‚   â”œâ”€â”€ embedding.py           # Vector embedding generation
â”‚   â”‚   â”œâ”€â”€ extraction.py          # Knowledge extraction (LLM)
â”‚   â”‚   â”œâ”€â”€ session.py             # Session detection & linking
â”‚   â”‚   â”œâ”€â”€ recommendation.py      # Recommendation scoring
â”‚   â”‚   â””â”€â”€ summarization.py       # Context summarization
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requests.py            # Pydantic request models
â”‚   â”‚   â””â”€â”€ responses.py           # Pydantic response models
â”‚   â”‚
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ extraction.py          # Knowledge extraction prompts
â”‚       â””â”€â”€ summarization.py       # Summarization prompts
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_db.sql               # PostgreSQL schema
â”‚   â”œâ”€â”€ migrate_db.sql             # Migration scripts
â”‚   â””â”€â”€ setup_neo4j.cypher         # Neo4j schema
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_chunking.py           # Chunking service tests
â”‚   â””â”€â”€ test_verification.py       # Verification tests
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ env.example                    # Environment template
â”œâ”€â”€ Dockerfile                     # Container definition
â””â”€â”€ README.md                      # This file
```

---

## ğŸ”’ Security

- **API Key Authentication** - All requests require valid API key
- **User Isolation** - Users can only access their own data
- **Row Level Security** - Enabled on all PostgreSQL tables
- **No PII in Logs** - Sensitive data is not logged

---

## ğŸ“ˆ Performance

| Operation | Latency |
|-----------|---------|
| Ingest | 3-8 sec |
| Retrieve (query) | 1-2 sec |
| Retrieve (session) | 1-3 sec |
| Recommend | 2-4 sec |

---

## ğŸ“ Learning Resources

### Understanding Embeddings
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- Embeddings capture semantic meaning, not just keywords
- Similar meanings â†’ similar vectors â†’ close in vector space

### Understanding pgvector
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- `<=>` operator = cosine distance
- IVFFlat index for fast approximate nearest neighbor search

### Understanding Neo4j
- [Neo4j Graph Database](https://neo4j.com/docs/)
- Nodes = Entities, Edges = Relationships
- Cypher query language for graph traversal

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<p align="center">
  <strong>Symmetry</strong> â€” Never lose context again.
</p>
